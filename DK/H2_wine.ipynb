{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NOTES:\n",
      "\n",
      "__a) Cross Validation and kNN__\n",
      "\n",
      "The wine dataset is in the data folder. To learn about the dataset, see the UCI repository page:\n",
      "\n",
      "http://archive.ics.uci.edu/ml/datasets/Wine\n",
      "\n",
      "i) Fit a kNN algorithm. Perform cross-validation to pick the best value for k.\n",
      "\n",
      "ii) Perform cross-validation to pick the best model between logistic regression and kNN. Does the answer change when you use a different CV technique?\n",
      "\n",
      "__b) Bias-Variance Framework__\n",
      "\n",
      "The example aims to the illustrate bias-variance framework. The ultimate goal is to achieve a respectable Eout. Hence, the model selection should be a function of availability of the data.\n",
      "\n",
      "Consider a case where target function is given by sin( \u03c0 x ) where the input distribution is uniform on [ -1, 1 ]. Assume that the training set has two examples and the learning algorithm tries to minize the mean squared error.\n",
      "\n",
      "Assume that we have two learning models consisting of all hypothesis in the form of:\n",
      "\n",
      "h(x) = ax + b\n",
      "\n",
      "h(x) = b\n",
      "\n",
      "Run 10,000 random trials and fit a line on each run.\n",
      "\n",
      "i) What is the average hypothesis for each model?\n",
      "\n",
      "ii) Report the bias and variance for both models. Which model generalizes better out-of-sample?\n",
      "\n",
      "__Hint(s):__\n",
      "\n",
      "i) Below the graphs on the left illustrate sample trials for each model. The charts on the right depict average hypotesis and variance of the models.\n",
      "\n",
      "ii) MSE can be defined as:\n",
      "\n",
      "def mse(y,h):\n",
      "    return(np.mean(np.square(y-h)))\n",
      "\n",
      "where y's are the target function variables and h's are your predictions based on your hypothesis over [-1, 1].    \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn import cross_validation as cv\n",
      "from sklearn.metrics import confusion_matrix, accuracy_score\n",
      "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
      "from sklearn.linear_model import LogisticRegression as LR\n",
      "\n",
      "# for 'height' deprecationwarning -- https://github.com/pydata/pandas/issues/4413\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
      "pd.__version__\n",
      "\n",
      "FILE = '../data/wine.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepare_wine(FILE):\n",
      "    '''Get data from txt file, put into dataframe, and extract (features, label).'''\n",
      "    \n",
      "    # read the file into dataframe and add column headers\n",
      "    wine = pd.read_csv('../data/wine.txt', header=None)\n",
      "    wine.columns = ['cultivar', 'alcohol', 'malic', 'ash', 'alcalinity', 'magnesium', \\\n",
      "                    'phenols', 'flavanoids','n_phenols', 'proanth', 'color', 'hue', \\\n",
      "                    'OD280_OD315', 'proline']\n",
      "    \n",
      "    # split data into features and label; drop na's\n",
      "    wine = wine.dropna()\n",
      "    features = wine.loc[:,'alcohol':'proline']\n",
      "    label = wine.loc[:,'cultivar']\n",
      "    \n",
      "    return features, label\n",
      "\n",
      "\n",
      "def find_k(data, steps=5, folds=5):\n",
      "    '''\n",
      "    Function to find best k for knn, with arguments data, steps, test_pct.\n",
      "    \n",
      "    data = tuple of (features, labels).\n",
      "    \n",
      "    steps = integer value specifying the number of odd k values to test starting from 1. \n",
      "    (Eg., steps = 2 results in testing k values [1, 3].) Defaults to 5.\n",
      "    \n",
      "    folds = number of folds for cross validation. Defaults to 5. \n",
      "    '''\n",
      "    \n",
      "    features, labels = data\n",
      "    \n",
      "    k_range = range(1,steps*2,2)\n",
      "    \n",
      "    scores = [[] for _ in k_range]\n",
      "    mean_scores = np.zeros(len(k_range))\n",
      "    \n",
      "    kfolds = cv.KFold(n=len(labels), n_folds=folds, shuffle=True)\n",
      "    \n",
      "    for idx, val in enumerate(k_range):\n",
      "        for i, (train_index, test_index) in enumerate(kfolds):\n",
      "            \n",
      "            features_train = features.iloc[train_index]\n",
      "            features_test = features.iloc[test_index]\n",
      "            \n",
      "            labels_train = labels.iloc[train_index]\n",
      "            labels_test = labels.iloc[test_index]\n",
      "            \n",
      "            kmeans = KNN(n_neighbors=val)\n",
      "            kmeans.fit(features_train, labels_train)\n",
      "            prediction = kmeans.predict(features_test)\n",
      "            scores[idx].append(accuracy_score(labels_test, prediction))\n",
      "        \n",
      "        print idx, scores[idx]\n",
      "        mean_scores[idx]=np.mean(scores[idx][:])\n",
      "        \n",
      "    best_k = k_range[np.argmax(mean_scores)]\n",
      "    print 'Best K for KNN is {0} neighbors.'.format(best_k)\n",
      "    print mean_scores\n",
      "    \n",
      "    return best_k\n",
      "\n",
      "\n",
      "def compare_models(data, best_k, ):\n",
      "    '''\n",
      "    \n",
      "    '''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = prepare_wine(FILE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_k = find_k(data, steps=12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 [0.75, 0.83333333333333337, 0.83333333333333337, 0.80000000000000004, 0.7142857142857143]\n",
        "1 [0.63888888888888884, 0.75, 0.66666666666666663, 0.8571428571428571, 0.68571428571428572]\n",
        "2 [0.69444444444444442, 0.75, 0.69444444444444442, 0.80000000000000004, 0.62857142857142856]\n",
        "3 [0.69444444444444442, 0.77777777777777779, 0.69444444444444442, 0.7142857142857143, 0.65714285714285714]\n",
        "4 [0.69444444444444442, 0.75, 0.69444444444444442, 0.82857142857142863, 0.7142857142857143]\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [0.66666666666666663, 0.69444444444444442, 0.66666666666666663, 0.8571428571428571, 0.62857142857142856]\n",
        "6 [0.69444444444444442, 0.75, 0.66666666666666663, 0.82857142857142863, 0.62857142857142856]\n",
        "7 [0.69444444444444442, 0.75, 0.66666666666666663, 0.82857142857142863, 0.62857142857142856]\n",
        "8 [0.77777777777777779, 0.75, 0.63888888888888884, 0.74285714285714288, 0.62857142857142856]\n",
        "9 [0.77777777777777779, 0.75, 0.66666666666666663, 0.7142857142857143, 0.65714285714285714]\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [0.77777777777777779, 0.75, 0.63888888888888884, 0.77142857142857146, 0.65714285714285714]\n",
        "11 [0.80555555555555558, 0.75, 0.63888888888888884, 0.80000000000000004, 0.62857142857142856]\n",
        "Best K for KNN is 1 neighbors.\n",
        "[ 0.78619048  0.71968254  0.71349206  0.70761905  0.73634921  0.70269841\n",
        "  0.71365079  0.71365079  0.70761905  0.7131746   0.71904762  0.72460317]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "whos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variable           Type        Data/Info\n",
        "----------------------------------------\n",
        "FILE               str         ../data/wine.txt\n",
        "KNN                ABCMeta     <class 'sklearn.neighbors<...>on.KNeighborsClassifier'>\n",
        "LR                 ABCMeta     <class 'sklearn.linear_mo<...>stic.LogisticRegression'>\n",
        "accuracy_score     function    <function accuracy_score at 0x10f176cf8>\n",
        "best_k             int         1\n",
        "confusion_matrix   function    <function confusion_matrix at 0x10f176aa0>\n",
        "cv                 module      <module 'sklearn.cross_va<...>rn/cross_validation.pyc'>\n",
        "data               tuple       n=2\n",
        "find_k             function    <function find_k at 0x10f5d7848>\n",
        "pd                 module      <module 'pandas' from '/u<...>ges/pandas/__init__.pyc'>\n",
        "pl                 module      <module 'pylab' from '/us<...>site-packages/pylab.pyc'>\n",
        "prepare_wine       function    <function prepare_wine at 0x10f5d7578>\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(data[0].columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "13"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}